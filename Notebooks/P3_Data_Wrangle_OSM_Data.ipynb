{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project 3: Data Wrangling Open Streetmaps Data\n",
    "---\n",
    "\n",
    "##References:\n",
    ">http://effbot.org/zone/element-iterparse.htm#incremental-parsing\n",
    "\n",
    ">https://www.aggdata.com/free/norway-postal-codes\n",
    "\n",
    "---\n",
    "\n",
    "##1. Problems encountered in the map\n",
    "####I decided to go for my hometown of Oslo, Norway, and naturally there was a bit of trouble with the non-English characters found there. I made two translation mappings, one for unicode and one for normal strings, for both small and capital æ,ø,å. Also, most of the addresses were missing a postal code.\n",
    "\n",
    "### Non-English characters\n",
    "#### The non-English characters in the dataset have different encodings, both unicode and standard. This called for two different approaches to translating these to the standard English representation of Scandinavian letters. I made two mappings in Python dicts, one for unicode and one for standard. Then, each streetname string was searched for the respective characters, and replaced with the English representation, e.g Ø was translated to Oe, æ was translated to ae. \n",
    "\n",
    "#### As an example, the name \"Bygdøy\" was translated to \"Bygdoey\".\n",
    "\n",
    "\n",
    "### Postal Codes\n",
    "#### A quite significant ammount of the entries (91,6%)  had postal code \"None\". I downloaded a spreadsheet with all post codes in Norway coupled with several positions from https://www.aggdata.com/free/norway-postal-codes. I removed those entries not from Oslo, saved as a csv and imported it with pandas. Taking a nearest-neighbour approach, I found the closest (L2-Norm) point with postal code for all those entries currently without a postal code, and made that the new postal code. Not always strictly correct of course, but better than nothing! \n",
    "#### I only did this for street addresses, since doing it for the entire data set would have been to heavy for my computer (finding nearest neighbour of 500k points to a set of 620 points).\n",
    "---\n",
    "\n",
    "##2. Overview of the data\n",
    "\n",
    "###File sizes\n",
    "#### oslo.osm .. 50,1 MB\n",
    "#### oslo.json .. 95,6 MB\n",
    "\n",
    "###Some selected data\n",
    "#### The number of documents in the set is 472,112, 417.088 of which are nodes and 55,024 are ways.\n",
    "db.oslo.find().count()\n",
    "list(db.oslo.aggregate(nodes_and_ways))\n",
    "\n",
    "nodes_and_ways = [{\"\\$group\":{\"_id\":\"\\$type\",\"count\":{\"\\$sum\":1 \\}\\}\\},{\"$sort\":{\"count\":-1}}]\n",
    "\n",
    "#### There are 454 distinct contributors, the most active being 'Turleder'n', who's commited 221,584 (46,9\\%)of the 472,112 documents.\n",
    "len(db.oslo.distinct('created.user'))\n",
    "list(db.oslo.aggregate(top_user))\n",
    "\n",
    "top_user = [{\"\\$group\":{\"_id\":\"\\$created.user\",\"count\":{\"\\$sum\":1\\}\\}\\},{\"\\$sort\":{\"count\":-1}},{\"\\$limit\":1}]\n",
    "\n",
    "#### There are 957 distinct street addresses in the set.\n",
    "len(db.oslo.distinct('address.street'))\n",
    "\n",
    "---\n",
    "\n",
    "##3. Other ideas about the dataset\n",
    "###Addresses per postal code\n",
    "####Though it would be interesting to see the number of addresses per top 5 postal codes, before and after the assignment algorithm had run on it.\n",
    "####Results before assignment from algorithm:\n",
    "None: 1223\n",
    "\n",
    "0374: 1060\n",
    "\n",
    "0375: 990\n",
    "\n",
    "0851: 842\n",
    "\n",
    "0373: 787\n",
    "\n",
    "####After algorithm\n",
    "0374: 1060\n",
    "\n",
    "0375: 992\n",
    "\n",
    "0851: 842\n",
    "\n",
    "0001: 840\n",
    "\n",
    "0373: 787\n",
    "\n",
    "####As we can see, most of the points were added to the post code 0001. \n",
    "\n",
    "#### I used the aggregation\n",
    "addresses_per_postal_code = [{\"\\$match\":{\"address\":{\"\\$exists\": True\\}\\}\\},{\"\\$group\":{\"_id\":\"\\$address.postcode\",\"count\":{\"\\$sum\":1}}},{\"\\$sort\":{\"count\":-1}\\},{\"$limit\":5}]\n",
    "\n",
    "###Different types of nodes\n",
    "#### 455 of the documents, with tag node or way, had a field for type in the dataset. I saved these types as type_2, and most of them turned out to be either individual(node) trees or lanes(way) of trees, all broad leaved trees.\n",
    "#### type_2 entries:\n",
    "#### broad_leaved, node: 411\n",
    "#### broad_leaved, way: 26\n",
    "#### Autopass, node: 12\n",
    "#### Route, way: 2\n",
    "#### public_transport, node: 2\n",
    "#### multi_polygon,way: 2\n",
    "\n",
    "####Found using:\n",
    "type_2 = [{\"\\$match\":{\"type_2\":{\"\\$exists\":True}}},{\"\\$group\":{\"_id\":{\"type\":\"\\$type\",\"type_2\":\"\\$type_2\"},\"count\":{\"\\$sum\":1}}},{\"\\$sort\":{\"count\":-1}}]\n",
    "\n",
    "###Dates of entries\n",
    "#### Having a look at the dates of the entries, we can see that most of the entries are from 2011, with 2014 coming in second. Histogram at the bottom of the submission.\n",
    "\n",
    "\n",
    "###Postal codes:\n",
    "#### It seems to have been a practice to not include postal code in a lot of the submissions. This could be changed by demanding an entry for the post code on certain entries. A better approach would be to obtain a sufficiently accurate mapping from position to postal code, and have it automatically added to the record upon submission. This should be pretty easy to implement (as long as such a mapping can be made), ensure data quality, all the while not making things any more complicated for the person submitting the entry.\n",
    "\n",
    "###Potential problem with translating characters\n",
    "####It's a posibility, however pretty rare, that when translating special characters to English standard, you'll change the old word into an already existing area name. In other words, there are distinct street names that would all of a sudden no longer be distinct. This could lead to confusion, and make the data less accurate. An option here is to add a new field informing that the name has been Englified whenever a letter has been changed, to distinguish between Overaa (Translated from Overå) vs. Overaa (not translated from anything).\n",
    "\n",
    "---\n",
    "\n",
    "##4. Conclusion\n",
    "#### The biggest problem found with the dataset is the almost complete lack of postal codes. I made an attempt at fixing this with my new code, but the resolution of points per postal code isn't very high, so it's highly likely that some points now have a wrong postal code. Whether a change like that is acceptable is hard to determine without knowing the application for the data, but I did it anyways.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "%pylab inline\n",
    "file_path = 'C:\\Users\\hakon.tromborg\\Data Analyst Nanodegree\\Data\\\\oslo.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "#json->MongoDB can't handle the Norwegian letters, so I'm mapping them to their official [a-z] equivalents for both unicode\n",
    "#and normal strings\n",
    "letter_map = {u\"Å\":'Aa',\n",
    "              u\"Ø\":'Oe',\n",
    "              u\"Æ\":'Ae',\n",
    "              u\"å\":\"aa\",\n",
    "              u\"ø\":\"oe\",\n",
    "              u\"æ\":\"ae\"}\n",
    "unicode_map = {u\"\\xc5\":'Aa',\n",
    "              u\"\\xd8\":'Oe',\n",
    "              u\"\\xc6\":'Ae',\n",
    "              u\"\\xe5\":\"aa\",\n",
    "              u\"\\xf8\":\"oe\",\n",
    "              u\"\\xe6\":\"ae\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Code to approximate the postcodes\n",
    "\n",
    "import pandas as pd\n",
    "#Downloaded poisitions for Oslo's post codes from \n",
    "#https://www.aggdata.com/free/norway-postal-codes\n",
    "df = pd.read_csv('C:\\Users\\hakon.tromborg\\Data Analyst Nanodegree\\Data\\\\postcode_oslo.csv')\n",
    "\n",
    "df['Postal Code String'] = (3*'0' +  df['Postal Code'].astype(str))\n",
    "f = lambda x: x[-4:]\n",
    "df['Postal Code String'] = df['Postal Code String'].apply(f)\n",
    "\n",
    "def get_post_code(lat,lon,df):\n",
    "    min = Inf\n",
    "    for x in xrange(df.shape[0]):\n",
    "        s = (double(lat)-df['Latitude'][x])**2+(double(lon)-df['Longitude'][x])**2\n",
    "        if(s<min):\n",
    "            min = s\n",
    "            best = df['Postal Code String'][x]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#From chapter 6\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        # get an iterable\n",
    "        context = ET.iterparse(file_in, events=(\"start\", \"end\"))\n",
    "\n",
    "        # turn it into an iterator\n",
    "        context = iter(context)\n",
    "        \n",
    "        # get the root element\n",
    "        event, root = context.next()\n",
    "        \n",
    "        \n",
    "        for _, element in context:\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                #fo.write(json.dumps(el) + \"\\n\")\n",
    "            root.clear()\n",
    "        fo.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element):\n",
    "    node = {}\n",
    "    \n",
    "    node['created'] = {}\n",
    "    if element.tag in [\"node\",\"way\"]:\n",
    "        node['type'] = element.tag\n",
    "        if element.tag == \"way\":\n",
    "            node['node_refs'] = []\n",
    "            for it in element.iter(\"nd\"):\n",
    "                node['node_refs'].append(it.attrib['ref'])\n",
    "\n",
    "        for a in element.attrib:\n",
    "            if a in CREATED:\n",
    "                node['created'][a] = element.attrib[a]\n",
    "            elif a == 'pos' or 'lat':\n",
    "                #Ensure 'pos' only shows up in documents with a latitude/longitude\n",
    "                if 'pos' not in node:\n",
    "                    node['pos'] = [\"0\",\"0\"]\n",
    "                if a == \"lat\":\n",
    "                    node['pos'][0]=(float(element.attrib[a]))\n",
    "                elif a == \"lon\":\n",
    "                    node['pos'][1]=(float(element.attrib[a]))\n",
    "            else:\n",
    "                node[a] = element.attrib[a]\n",
    "                \n",
    "\n",
    "        for it in element.iter(\"tag\"):\n",
    "            #Skip the iteration and drop the element if problemchars are discovered\n",
    "            e = problemchars.search(it.attrib['k'])\n",
    "            if e:\n",
    "                continue\n",
    "                \n",
    "            elif it.attrib['k'][:5] == \"addr:\":\n",
    "                if 'address' not in node:\n",
    "                    node['address'] = {}\n",
    "                c = it.attrib['k'].split(':')\n",
    "                \n",
    "                #If c is 2, there's exactly one : in the string, which is the format we're looking for\n",
    "                if len(c) == 2:\n",
    "                    translated_string = translate_string(it.attrib['v'])\n",
    "                    #Translating Norwegian letters proved more difficult than expected \n",
    "                    #because the set contains both unicode and normal strings\n",
    "                    node['address'][it.attrib['k'][5:]] = translated_string\n",
    "            elif (it.attrib['k'] == \"type\") and (it.attrib['k'] not in [\"node\",\"way\"]) :\n",
    "                node['type_2'] = it.attrib['v']\n",
    "            \n",
    "            else:    \n",
    "                node[it.attrib['k']] = it.attrib['v']\n",
    "        if 'address' in node:\n",
    "            if 'postcode' not in node['address']:\n",
    "                node['address']['postcode'] = get_post_code(node['pos'][0],node['pos'][1],df)\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def translate_string(str):\n",
    "    if type(str) is unicode:\n",
    "        translated_string = translate_unicode(str)\n",
    "        return translated_string\n",
    "    else:\n",
    "        translated_string = translate_utf(str)\n",
    "        return translated_string\n",
    "    \n",
    "def translate_unicode(addr):\n",
    "    for l in unicode_map:\n",
    "        if l in list(addr):\n",
    "            #using if l in letter_map crashes with unicode characters because illegal decodings are attempted\n",
    "            addr = [c.replace(l, unicode_map[l]) for c in list(addr)]\n",
    "            addr = ''.join(addr)\n",
    "    return addr\n",
    "def translate_utf(addr):\n",
    "    for l in letter_map:\n",
    "        if l in addr:\n",
    "            addr = addr.replace(l,letter_map[l])\n",
    "    return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_file():\n",
    "    data = process_map(file_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.1920001507\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "process_file()\n",
    "print time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "OSM_FILE = file_path  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"C:\\Users\\hakon.tromborg\\Data Analyst Nanodegree\\Data\\\\oslo_sample.osm\"\n",
    "\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every 10th top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % 10 == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_data(data, db):\n",
    "    db.oslo.insert(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.876999855\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.oslo\n",
    "#Clear the database to avoid adding multiple records\n",
    "db.oslo.remove()\n",
    "\n",
    "t0 = time.time()\n",
    "with open(file_path + '.json') as f:\n",
    "        data = json.loads(f.read())\n",
    "        insert_data(data, db)\n",
    "print time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:\n",
      "472112\n",
      "Number of nodes and ways:\n",
      "[{u'_id': u'node', u'count': 417088}, {u'_id': u'way', u'count': 55024}]\n",
      "Number of unique users:\n",
      "454\n",
      "Top contributing user:\n",
      "[{u'count': 221584, u'_id': u\"Turleder'n\"}]\n",
      "Distinct street addresses in set:\n",
      "957\n",
      "Distinct postal codes: \n",
      "215\n",
      "Number of addresses per postal code: \n",
      "[{u'count': 1064, u'_id': u'0374'}, {u'count': 992, u'_id': u'0375'}, {u'count': 842, u'_id': u'0851'}, {u'count': 840, u'_id': u'0001'}, {u'count': 787, u'_id': u'0373'}]\n"
     ]
    }
   ],
   "source": [
    "nodes_and_ways = [{\"$group\":{\"_id\":\"$type\",\n",
    "                      \"count\":{\"$sum\":1}}},\n",
    "            {\"$sort\":{\"count\":-1}}\n",
    "                 ]\n",
    "\n",
    "top_user = [{\"$group\":{\"_id\":\"$created.user\",\n",
    "                            \"count\":{\"$sum\":1}}},\n",
    "                           {\"$sort\":{\"count\":-1}},\n",
    "                           {\"$limit\":1}]\n",
    "addresses_per_postal_code = [{\"$match\":{\"address\":{\"$exists\": True}}},\n",
    "                            {\"$group\":{\"_id\":\"$address.postcode\",\n",
    "                            \"count\":{\"$sum\":1}}},\n",
    "                           {\"$sort\":{\"count\":-1}},\n",
    "                            {\"$limit\":5}]\n",
    "\n",
    "print \"Number of records:\"\n",
    "print db.oslo.find().count()\n",
    "\n",
    "print \"Number of nodes and ways:\"\n",
    "pprint.pprint(list(db.oslo.aggregate(nodes_and_ways)))\n",
    "\n",
    "print \"Number of unique users:\"\n",
    "print len(db.oslo.distinct('created.user'))\n",
    "\n",
    "print \"Top contributing user:\"\n",
    "print list(db.oslo.aggregate(top_user))\n",
    "\n",
    "print \"Distinct street addresses in set:\"\n",
    "print len(db.oslo.distinct('address.street'))\n",
    "\n",
    "print \"Distinct postal codes: \"\n",
    "print len(db.oslo.distinct('address.postcode'))\n",
    "\n",
    "print \"Number of addresses per postal code: \"\n",
    "print list(db.oslo.aggregate(addresses_per_postal_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 431677, u'_id': u\"address'postcode\"}]\n",
      "[{u'count': 411, u'_id': {u'type_2': u'broad_leaved', u'type': u'node'}}, {u'count': 26, u'_id': {u'type_2': u'broad_leaved', u'type': u'way'}}, {u'count': 12, u'_id': {u'type_2': u'Autopass', u'type': u'node'}}, {u'count': 2, u'_id': {u'type_2': u'multipolygon', u'type': u'way'}}, {u'count': 2, u'_id': {u'type_2': u'route', u'type': u'way'}}, {u'count': 2, u'_id': {u'type_2': u'public_transport', u'type': u'node'}}]\n"
     ]
    }
   ],
   "source": [
    "addresses_no_postal_code = [{\"$match\":{\"address.postcode\":None}},\n",
    "                            {\"$group\":{\"_id\":\"address'postcode\",#{\"type\":\"$type\",\"type_2\":\"$type_2\"},\n",
    "                            \"count\":{\"$sum\":1}}},\n",
    "                           {\"$sort\":{\"count\":-1}},\n",
    "                            {\"$limit\":10}]\n",
    "\n",
    "type_2 = [{\"$match\":{\"type_2\":{\"$exists\":True}}},\n",
    "                            {\"$group\":{\"_id\":{\"type\":\"$type\",\"type_2\":\"$type_2\"},\n",
    "                            \"count\":{\"$sum\":1}}},\n",
    "                           {\"$sort\":{\"count\":-1}}\n",
    "                            ]\n",
    "\n",
    "print list(db.oslo.aggregate(addresses_no_postal_code))\n",
    "\n",
    "\n",
    "print list(db.oslo.aggregate(type_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000000000BC00A20>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMNMIvIsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x50ce1e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "times = db.oslo.distinct('created.timestamp')\n",
    "for x,t in enumerate(times):\n",
    "    times[x] = int(times[x][:4])\n",
    "#print sorted(times)\n",
    "d = pd.DataFrame(sorted(times))\n",
    "d.hist(bins = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
